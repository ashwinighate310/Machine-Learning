{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the  Hue-Saturation-Value of the colour according to your cloth colour\n",
    "RGB image has mixed intensity and color information for different color channels \n",
    "HSV color has separate information of the color and intensity from each other. This makes HSV color space more robust to lighting changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV reads a given image in the BGR format by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording from the webcam\n",
    "cap_video = cv2.VideoCapture(0)\n",
    "w = cap_video.get(cv2.CAP_PROP_FRAME_WIDTH);\n",
    "h = cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT); \n",
    "\n",
    "# writing the ouput video object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "result = cv2.VideoWriter('cloak_output.mp4', fourcc, 20.0, (int(w),int(h)))\n",
    "    \n",
    "# set the camera sleep time to 2 & background to 0, before starting\n",
    "time.sleep(2)\n",
    "count = 0\n",
    "background = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save background image, Capture the background in range of 60\n",
    "\n",
    "for i in range(60):\n",
    "    out_val, background = cap_video.read()\n",
    "    if out_val == False :\n",
    "        continue\n",
    "\n",
    "# flip the background frame\n",
    "background = np.flip(background, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphology needs two inputs, one is original image, second one is called structuring element or kernel which decides the nature of operation. \n",
    "it has 2 basic operators Erosion and Dilation. \n",
    "\n",
    "Erosion erodes away the boundaries of foreground object.A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "So the thickness or size of the foreground object decreases.It is useful for removing small white noises.\n",
    "\n",
    "Dilation increases the object area. A pixel element is '1' if atleast one pixel under the kernel is '1'. \n",
    "\n",
    "We will do a morphology open ( erosion followed by dilation) and dilation for replacing the covered coloured object portion with a mask image in each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the background from the webcamera, until camera is open\n",
    "while (cap_video.isOpened()):\n",
    "    out_val, pic = cap_video.read()\n",
    "    if not out_val:\n",
    "        break\n",
    "    count += 1\n",
    "    pic = np.flip(pic, axis=1)\n",
    "    \n",
    "    # For more robust to lighting changes, Converting the color space from BGR to HSV\n",
    "    hsv = cv2.cvtColor(pic, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "  # Generate masks to detect  color, setting the lower and upper range for mask1 \n",
    "    lower_pink = np.array([100, 100, 30])        \n",
    "    upper_pink = np.array([10, 255, 255]) \n",
    "    mask1 = cv2.inRange(hsv, lower_pink, upper_pink) \n",
    "    # setting the lower and upper range for mask2  \n",
    "    lower_pink = np.array([125, 100, 30]) \n",
    "    upper_pink = np.array([255, 255, 255]) \n",
    "    mask2 = cv2.inRange(hsv, lower_pink, upper_pink) \n",
    "    \n",
    "    final_mask = mask1 + mask2\n",
    "    \n",
    "    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations = 2)\n",
    "    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_DILATE, np.ones((3, 3), np.uint8), iterations = 1)\n",
    "    \n",
    "        # bitwise_not operation will create an inverted mask to separate out the covered object color from the frame\n",
    "    inv_mask = cv2.bitwise_not(final_mask)\n",
    "\n",
    "    # bitwise_and operation with the inverted mask will separate the color part out of the frame\n",
    "    out_img1 = cv2.bitwise_and(pic, pic, mask=inv_mask)\n",
    "\n",
    "    # bitwise_and operation will create image showing static background frame only for the masked region\n",
    "    out_img2 = cv2.bitwise_and(background, background, mask=final_mask)\n",
    "\n",
    "     # Generating the final output \n",
    "    Output = cv2.addWeighted(out_img1, 1, out_img2, 1, 0)\n",
    "    #Output = cv2.resize(Output, (800, 600))\n",
    "    \n",
    "    #fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    #result = cv2.VideoWriter('cloak_output.avi', fourcc, 20.0, (int(w),int(h)))\n",
    "    \n",
    "    result.write(Output)\n",
    "    \n",
    "    cv2.imshow(\"Invisible Cloak\", Output)\n",
    "    key = cv2.waitKey(25)\n",
    "    if key == ord('n') or key == ord('p'):\n",
    "        break\n",
    "\n",
    "cap_video.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
