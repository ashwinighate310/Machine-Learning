{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_lists = ['https://www.dissentmagazine.org/online-articles/page/2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dissentmagazine.org/online-articles/page/2\n",
      "https://www.dissentmagazine.org/online-articles/page/3\n",
      "https://www.dissentmagazine.org/online-articles/page/4\n",
      "https://www.dissentmagazine.org/online-articles/page/5\n",
      "https://www.dissentmagazine.org/online-articles/page/6\n",
      "https://www.dissentmagazine.org/online-articles/page/7\n",
      "https://www.dissentmagazine.org/online-articles/page/8\n",
      "https://www.dissentmagazine.org/online-articles/page/9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<title>Online Articles | Dissent Magazine</title>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_lists=[]\n",
    "for i in range(2,10):    \n",
    "    url = \"https://www.dissentmagazine.org/online-articles/page/{}\".format(i)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    #select only h3 tags with class flow-text and then select its child a \n",
    "    for j in soup.select(\"h3.flow-text > a\"):\n",
    "        article_url=j.get('href')\n",
    "        url_lists.append(article_url)\n",
    "        #print(j.get('href'))\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dissentmagazine.org/online-articles/page/2\n",
      "https://www.dissentmagazine.org/online-articles/page/3\n",
      "https://www.dissentmagazine.org/online-articles/page/4\n",
      "https://www.dissentmagazine.org/online-articles/page/5\n",
      "https://www.dissentmagazine.org/online-articles/page/6\n",
      "https://www.dissentmagazine.org/online-articles/page/7\n",
      "https://www.dissentmagazine.org/online-articles/page/8\n",
      "https://www.dissentmagazine.org/online-articles/page/9\n"
     ]
    }
   ],
   "source": [
    "def getpostlinks(url_lists):    \n",
    "    for i in range(2,10): \n",
    "        url = \"https://www.dissentmagazine.org/online-articles/page/{}\".format(i)\n",
    "        print(url)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "    \n",
    "        #select only h3 tags with class flow-text and then select its child a \n",
    "        for j in soup.select(\"h3.flow-text > a\"):\n",
    "            article_url=j.get('href')\n",
    "            url_lists.append(article_url)\n",
    "    return\n",
    "\n",
    "url_lists=[]\n",
    "getpostlinks(url_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpostText(Url):\n",
    "    page = Request(Url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    html_page = urlopen(Url).read().decode('utf8','ignore') \n",
    "    soup = BeautifulSoup(html_page, 'html.parser')    \n",
    "    for j in soup.findAll(\"section\", {\"id\":'article'}):\n",
    "        article=j.find_all('p') # select para with tag p inside section with id as article\n",
    "    \n",
    "        for k in article:\n",
    "            text=k.get_text().replace(\"?\",\" \") # get the text from each para tag\n",
    "            articlePosts.append(text)\n",
    "            #print (text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlePosts = []\n",
    "for link in url_lists:\n",
    "    articlePosts+=getpostText(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benjamin Netanyahu has used the coronavirus to resuscitate his political career.',\n",
       " 'On March 2, Israelis went to the polls for their country’s third national election in less than a year. Many of them hoped to vote out Prime Minister Benjamin Netanyahu, whose eleven consecutive\\xa0years in power have been marked by a series of corruption scandals and an increasingly right-wing turn. At the time, the country was just waking up to the threat of coronavirus. Thousands of Israelis in quarantine received permission to leave their homes to vote in special polling tents. Everyone else cast their ballots as usual. Now, nearly a month later, most Israeli citizens are barred from traveling more than 100 meters (330 feet) from their homes, and Netanyahu has found a way to use the coronavirus situation to his advantage.',\n",
       " 'Israel appears to be swiftly moving toward a ruling coalition led—at least initially—by Netanyahu, even though his right-wing bloc did not come out of the most recent election with a majority. Netanyahu’s main rival, Benny Gantz of the Blue and White party, is reportedly negotiating a rotation agreement with his former foe, breaking his promise not to sit with Netanyahu because of the prime minister’s corruption charges.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articlePosts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "#list(get_stop_words('en')\n",
    "\n",
    "adhoc_list=['de', 'la', 'en', 'el', 'los', 'que', 'amlo', 'un', 'del', 'las','’','“','—','”','new','one','would','also','like','left','many','away','upon','de']\n",
    "stop_word = set(stopwords.words('english') + list(get_stop_words('en'))+list(punctuation)+list(adhoc_list)+[\"'s\",\"''\",\"``\",\"sign\",\"newsletter\"])\n",
    "#stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6058x686 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer object, within that specify stopwords\n",
    "# min_df = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "#max_df = 0.80 means \"It ignores terms that appear in more than 80% of the documents\".\n",
    "vectorizer = TfidfVectorizer(max_df=.8,min_df=0.005,stop_words=stop_word)\n",
    "# vectorizer fit_transform method takes a list of strings and then returns a two-dimensional array.Each row represents one document\n",
    "X = vectorizer.fit_transform(articlePosts)\n",
    "# So 6058 here represents the total number of articles & 686 distinct word in each articlein our corpus. \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x686 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of columns represents the number of distinct words which are present in all articles.\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 640)\t0.6157444642196925\n",
      "  (0, 121)\t0.6617006061155091\n",
      "  (0, 449)\t0.4277979226798229\n"
     ]
    }
   ],
   "source": [
    "# X of zero will be a tuple of 686 numbers where each number represents the term frequency multiplied by inverse document frequency of one word.\n",
    "print (X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 2505.713\n",
      "Iteration  1, inertia 2465.477\n",
      "Iteration  2, inertia 2457.493\n",
      "Iteration  3, inertia 2456.265\n",
      "Iteration  4, inertia 2455.997\n",
      "Iteration  5, inertia 2455.943\n",
      "Converged at iteration 5: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2508.779\n",
      "Iteration  1, inertia 2471.064\n",
      "Iteration  2, inertia 2465.691\n",
      "Iteration  3, inertia 2463.513\n",
      "Iteration  4, inertia 2462.878\n",
      "Iteration  5, inertia 2462.386\n",
      "Iteration  6, inertia 2462.261\n",
      "Iteration  7, inertia 2462.246\n",
      "Iteration  8, inertia 2462.233\n",
      "Converged at iteration 8: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2413.169\n",
      "Iteration  1, inertia 2369.728\n",
      "Iteration  2, inertia 2356.471\n",
      "Iteration  3, inertia 2353.837\n",
      "Iteration  4, inertia 2353.106\n",
      "Iteration  5, inertia 2352.889\n",
      "Iteration  6, inertia 2352.721\n",
      "Iteration  7, inertia 2352.708\n",
      "Iteration  8, inertia 2352.692\n",
      "Iteration  9, inertia 2352.678\n",
      "Iteration 10, inertia 2352.665\n",
      "Converged at iteration 10: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2509.660\n",
      "Iteration  1, inertia 2472.153\n",
      "Iteration  2, inertia 2468.761\n",
      "Iteration  3, inertia 2467.750\n",
      "Iteration  4, inertia 2467.322\n",
      "Iteration  5, inertia 2467.113\n",
      "Iteration  6, inertia 2466.978\n",
      "Iteration  7, inertia 2466.948\n",
      "Iteration  8, inertia 2466.935\n",
      "Converged at iteration 8: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2509.643\n",
      "Iteration  1, inertia 2476.618\n",
      "Iteration  2, inertia 2468.729\n",
      "Iteration  3, inertia 2466.057\n",
      "Iteration  4, inertia 2465.876\n",
      "Iteration  5, inertia 2465.824\n",
      "Iteration  6, inertia 2465.772\n",
      "Iteration  7, inertia 2465.751\n",
      "Iteration  8, inertia 2465.731\n",
      "Converged at iteration 8: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2509.584\n",
      "Iteration  1, inertia 2478.796\n",
      "Iteration  2, inertia 2478.364\n",
      "Iteration  3, inertia 2478.100\n",
      "Iteration  4, inertia 2477.314\n",
      "Iteration  5, inertia 2475.510\n",
      "Iteration  6, inertia 2474.233\n",
      "Iteration  7, inertia 2473.146\n",
      "Iteration  8, inertia 2472.082\n",
      "Iteration  9, inertia 2470.624\n",
      "Iteration 10, inertia 2469.652\n",
      "Iteration 11, inertia 2468.020\n",
      "Iteration 12, inertia 2463.472\n",
      "Iteration 13, inertia 2456.487\n",
      "Iteration 14, inertia 2444.664\n",
      "Iteration 15, inertia 2436.890\n",
      "Iteration 16, inertia 2434.741\n",
      "Iteration 17, inertia 2434.370\n",
      "Iteration 18, inertia 2434.318\n",
      "Iteration 19, inertia 2434.304\n",
      "Iteration 20, inertia 2434.288\n",
      "Iteration 21, inertia 2434.277\n",
      "Iteration 22, inertia 2434.263\n",
      "Iteration 23, inertia 2434.258\n",
      "Iteration 24, inertia 2434.251\n",
      "Iteration 25, inertia 2434.245\n",
      "Iteration 26, inertia 2434.243\n",
      "Converged at iteration 26: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2509.066\n",
      "Iteration  1, inertia 2471.764\n",
      "Iteration  2, inertia 2466.782\n",
      "Iteration  3, inertia 2465.025\n",
      "Iteration  4, inertia 2464.535\n",
      "Iteration  5, inertia 2464.051\n",
      "Iteration  6, inertia 2463.952\n",
      "Iteration  7, inertia 2463.937\n",
      "Iteration  8, inertia 2463.923\n",
      "Converged at iteration 8: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2509.696\n",
      "Iteration  1, inertia 2474.640\n",
      "Iteration  2, inertia 2472.032\n",
      "Iteration  3, inertia 2470.922\n",
      "Iteration  4, inertia 2470.572\n",
      "Iteration  5, inertia 2470.419\n",
      "Iteration  6, inertia 2470.339\n",
      "Converged at iteration 6: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2510.000\n",
      "Iteration  1, inertia 2479.922\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 5.974508e-08\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2510.000\n",
      "Iteration  1, inertia 2479.932\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 5.974508e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=150,\n",
       "    n_clusters=4, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_clusters specify the number of clusters,we want to divide our articles into groups. \n",
    "# The init specifies an algorithm to help choose the initial centroids in such a way that we can find the relevant clusters with a minimum number of iterations. \n",
    "\n",
    "k_means = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 150, verbose = True)\n",
    "k_means.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([  76,   86, 5794,  102]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every document in array X has now been assigned a number, which represents the cluster to which it belongs\n",
    "# So cluster zero has 76 articles. Cluster 1 has 86 and cluster 2 has 5794 articles\n",
    "np.unique(k_means.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary 'text' in which the keys will be the cluster numbers and the values will be the aggregated text across all the articles which are present\n",
    "text={}\n",
    "for i,cluster in enumerate(k_means.labels_):\n",
    "    article_tag = articlePosts[i]\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = article_tag\n",
    "    else:\n",
    "        text[cluster] += article_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each cluster and take the corresponding text and tokenize it into words.filter out all the stop words\n",
    "# pick the top 100 words using frequency distribution and get corrsponding counts\n",
    "keywords = {}\n",
    "word_counts={}\n",
    "for cluster in range(3):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent=[word for word in word_sent if word not in stop_word]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    word_counts[cluster]=freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 10 keywords which are unique to each cluster\n",
    "unique_keys={}\n",
    "for cluster in range(3):   \n",
    "    other_clusters=list(set(range(3))-set([cluster]))\n",
    "    keys_other_clusters=set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n",
    "    unique=set(keywords[cluster])-keys_other_clusters\n",
    "    unique_keys[cluster]=nlargest(10, unique, key=word_counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['housing',\n",
       "  'rent',\n",
       "  'land',\n",
       "  'tenants',\n",
       "  'development',\n",
       "  'homes',\n",
       "  'supply',\n",
       "  'market',\n",
       "  'prices',\n",
       "  'affordability'],\n",
       " 1: ['hong',\n",
       "  'kong',\n",
       "  'china',\n",
       "  'chinese',\n",
       "  'international',\n",
       "  'protests',\n",
       "  'beijing',\n",
       "  'bill',\n",
       "  'police',\n",
       "  'protesters'],\n",
       " 2: ['power',\n",
       "  'trump',\n",
       "  'states',\n",
       "  'party',\n",
       "  'united',\n",
       "  'workers',\n",
       "  'politics',\n",
       "  'national',\n",
       "  'history',\n",
       "  'american']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = \"A group of 30 Kenyan runners from across the country ran solo half marathons to compete in a virtual race amid coronavirus pandemic. They had been training for Wuhan Marathon which was to be held this week but got postponed. As a part of CoronaRun organised in Kenya, runners ran a 21-km course and recorded their time using GPS watches.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit method to set up the training phase to parse in the complete set of articles for which the labels are already known.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X,k_means.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used vectorizer. transform to convert the article into the TF-IDF form.\n",
    "sample=vectorizer.transform([snippet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x686 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the predict method of the classifier to assign a theme for snippet\n",
    "classifier.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
